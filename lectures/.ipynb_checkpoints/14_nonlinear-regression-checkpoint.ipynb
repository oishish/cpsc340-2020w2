{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPSC 340 Lecture 14: nonlinear regression\n",
    "\n",
    "This notebook is for the in-class activities. It assumes you have already watched the [associated video](https://www.youtube.com/watch?v=Z1O7BGDq2ik&list=PLWmXHcz_53Q02ZLeAxigki1JZFfCO6M-b&index=13)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**REMINDER TO START RECORDING**</font>\n",
    "\n",
    "Also, reminder to enable screen sharing for Participants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-class music\n",
    "\n",
    "Lingus by Snarky Puppy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admin\n",
    "\n",
    "- a3 in progress\n",
    "- We didn't have much time left to talk about the data space vs. parameter space last time - please review if needed.\n",
    "- A lot of content in today's lecture as well ðŸ˜…\n",
    "- Countdown to reading week: 2 more classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video chapters\n",
    "\n",
    "- smooth approximations \n",
    "- loss functions recap\n",
    "- nonlinear regression\n",
    "- polynomial features\n",
    "- robust regression demo\n",
    "- polynomial regression demo\n",
    "- other non-linear transforms\n",
    "- RBF intro\n",
    "- RBF demo\n",
    "- RBF details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old exam questions\n",
    "\n",
    "I will order these by topic instead of chronologically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth approximations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From 2018W1 midterm\n",
    "\n",
    "Consider the loss function $f(r) = \\sum^n_{i=1} \\max\\{r_i,âˆ’2r_i\\}$. Write down a version of this loss\n",
    "function that is smoothed with the log-sum-exp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mike's answer:** $f(r) = \\sum_{i=1}^n \\log \\left( \\exp(r_i) + \\exp(-2r_i)  \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From 2018W1 midterm\n",
    "\n",
    "![](img/L14/poly_a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mike's answer:**\n",
    "\n",
    "Z = \n",
    "\n",
    "```\n",
    "1  -3   9 \n",
    "1   4  16\n",
    "1  -1   1\n",
    "1   3   9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/L14/poly_b.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mike's answer:** \n",
    "\n",
    "$\\tilde{z} = [1 \\quad 2 \\quad  4]^T$\n",
    "\n",
    "$v^T \\tilde{z} = -1 \\times 1 + 3 \\times 2 + 0 \\times 4 = 5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/L14/poly_c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mike's answer:** Yes for this specific case because the last element of $v$ is zero. For any general $v$ it wouldn't necessarily be true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From 2018W1 midterm\n",
    "\n",
    "When we do regression with a polynomial basis, how does the degree of the polynomial $p$ affect the two parts of the fundamental trade-off?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mike's answer:** Increasing $p$ leads to lower training error & higher approximation error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From 2018W1 final\n",
    "\n",
    "For linear regression with $d = 1$ using a polynomial basis of degree $p$,  how many trainable parameters does the model have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mike's answer:** $p+1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From 2016W2 final\n",
    "\n",
    "The following code attempts to use a polynomial (quadratic) basis where $d = 1$ (so `X` is a column vector) to train/test a regression model.\n",
    "However, the code contains a serious flaw. Briefly explain the problem and how you would fix it. You can assume numpy has been imported (`import numpy as np`) and the variables `n`, `d`, `X`, `y`, `Xtest`, `ytest` and `model` have been properly defined in the usual way.\n",
    "\n",
    "Hint: the flaw is conceptual rather than a python/numpy syntax issue.\n",
    "\n",
    "```python\n",
    "Z = np.zeros((n,3))\n",
    "Z[:,0] = 1\n",
    "Z[:,1] = X\n",
    "Z[:,2] = X**2\n",
    "model.fit(Z, y)\n",
    "training_error = np.sum((model.predict(Z)-y)**2) \n",
    "test_error = np.sum((model.predict(Xtest)-ytest)**2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mike's answer:** we need to transform `Xtest` to `Ztest` before passing it into `predict`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From 2016W2 midterm\n",
    "\n",
    "For ordinary least squares linear regression with RBF features, what is the space complexity of the trained model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mike's answer:** $O(nd)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From 2017W2 midterm\n",
    "\n",
    "Name one advantage and one disadvantage of using RBF features over polynomial features with linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mike's answer:**\n",
    "\n",
    "- Advantage: can learn more complex fits, achieve lower training error (and hopefully lower test error for complex datasets).\n",
    "- Disadvantage: computational issues (memory usage, slow for large $n$); may overfit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student questions\n",
    "\n",
    "https://edstem.org/us/courses/3226/discussion/245940"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
