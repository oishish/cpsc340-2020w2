{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPSC 340 Lecture 11: linear regression: `predict`\n",
    "\n",
    "This notebook is for the in-class activities. It assumes you have already watched the [associated video](https://www.youtube.com/watch?v=PBUIPTDSPQE&list=PLWmXHcz_53Q02ZLeAxigki1JZFfCO6M-b&index=10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**REMINDER TO START RECORDING**</font>\n",
    "\n",
    "Also, reminder to enable screen sharing for Participants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's pre-class songs\n",
    "\n",
    "1. Vienna by Billy Joel\n",
    "2. Lover Boy by Phum Viphurit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admin\n",
    "\n",
    "- a2 due tonight\n",
    "- Per [Ed post](https://edstem.org/us/courses/3226/discussion/232386), you may be interested in [this data science terminology document](https://ubc-mds.github.io/resources_pages/terminology/).\n",
    "- Amit (TA) will join lecture today and will be available to answer questions / join breakout rooms. We can do a poll at the end of class to see if this is worth continuing.\n",
    "- Amit will also have office hours right after lecture today (and recurring on Wednesdays).\n",
    "- Countdown to reading week: 5 more classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video chapters\n",
    "\n",
    "- regression intro\n",
    "- simple linear regression\n",
    "- terminology woes\n",
    "- least squares objective\n",
    "- minimizing squared error in 1d\n",
    "- multiple linear regression\n",
    "- preparations for least squares in d dimensions\n",
    "- the y-intercept\n",
    "- summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old exam questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the 2016W1 midterm\n",
    "\n",
    "![](img/L11/2016w1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "$\\left(\\frac{2}{3}\\right) 9 - \\left(\\frac{1}{4}\\right) 4 = 5$\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also from the 2016W2 midterm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following methods are sensitive to the normalization of the features? For example, if one of your features is length, which methods would give different results if the unit of length is changed from metres to centimetres across all the (train and test) data?\n",
    "\n",
    "- KNN classifier\n",
    "- linear regression\n",
    "- decision tree\n",
    "- random forest\n",
    "- $k$-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    " - KNN: very sensitive. Interplay of different units is a big deal here.\n",
    " - Linear regression: completely insensitive. _Note this will become false in later version of regression that we do_\n",
    " - Decision tree: completely insensitive.\n",
    " - Random forest: based on DT, insensitive. \n",
    " - $k$-means: very sensitive.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the 2017W2 midterm\n",
    "\n",
    "What is the time complexity of predicting on a single test instance with linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "O(d). It is simply a matter of multiplication. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also from the 2017W2 midterm\n",
    "\n",
    "![](img/L11/lrprediction.png)\n",
    "\n",
    "Using the above weights $w$, the prediction for the test vector $\\tilde{x}_1$ is $\\hat{y}_1 = 10$. Find the prediction for the test vector $\\tilde{x}_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "$$\n",
    "    2a + 1300b + 3c + 3d - 5e = 10 \\\\\n",
    "    \\therefore 2(a+2) + 1300b + 3c + 3d - 5(e+1) = (2a + 1300b + 3c + 3d - 5e) + 4 - 5 = 10 + 4 - 5 = 9\n",
    "$$\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the 2018W1 midterm\n",
    "\n",
    "Describe a situation where using a linear regression model with the squared error could give very misleading results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Extreme outlier situations. Take the following example. Fit the following $X$ and $y$.\n",
    "$$\n",
    "    X = [1,2,3,4]; y = [1,2,3,10000000000]\n",
    "$$\n",
    "What should be a simple linear fit + an outlier, would end up extremely skewed by the existence of that outlier.\n",
    "\n",
    "Also, data that does not fit into a linear fit.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Time permitting) Student questions\n",
    "\n",
    "https://edstem.org/us/courses/3226/discussion/231959"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
