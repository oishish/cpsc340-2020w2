{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPSC 340 Lecture 8: $k$-means clustering\n",
    "\n",
    "This notebook is for the in-class activities. It assumes you have already watched the [associated video](https://www.youtube.com/watch?v=tCHjHCh-5PM&list=PLWmXHcz_53Q02ZLeAxigki1JZFfCO6M-b&index=7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**REMINDER TO START RECORDING**</font>\n",
    "\n",
    "Also, reminder to enable screen sharing for Participants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's pre-class songs\n",
    "\n",
    "1. Good Days by SZA\n",
    "2. Making Me Nervous by Brad Sucks (needed to swap in something a bit shorter so we can start on time!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admin\n",
    "\n",
    "- I updated the L7 notebook with the decision boundaries for the random trees inside a random forest.\n",
    "- https://edstem.org/us/courses/3226/discussion/223025\n",
    "- https://edstem.org/us/courses/3226/discussion/222837\n",
    "- Countdown to reading week: 8 more classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video chapters\n",
    "\n",
    "- random forest decision boundaries\n",
    "- model averaging demo\n",
    "- XGBoost demo\n",
    "- unsupervised learning\n",
    "- clustering intro\n",
    "- k-means intro\n",
    "- k-means demo\n",
    "- k-means outputs\n",
    "- k-means initializations\n",
    "- k-means issues\n",
    "- k-means as minimization\n",
    "- k-means cost\n",
    "- shape of clusters\n",
    "- DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old exam questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From 2016W2 midterm\n",
    "\n",
    "What is the space complexity of a trained $k$-means clustering model? Your answer may depend on $n$, $d$, and/or $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Should be $O(dk)$. Its basically KNN with the K-means we have already calculated. As such, there are $k$ vetors to store?, each one costs $O(d)$.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From 2017W2 midterm\n",
    "\n",
    "![](img/L8/clusterquestion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "(a) $n = 7$,  $d = 2$, $k = 3$\n",
    "\n",
    "(b) Just calculate euclidean distances. [3 1] is smallest distance $\\sqrt{10}$. Cluster 2.    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From 2018W1 midterm\n",
    "\n",
    "- Does it make sense to do $k$-means clustering with $k>n$? Briefly justify your answer.\n",
    "- Does it make sense to do $k$-means clustering with $k>d$? Briefly justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "No thats makes no sense. More means than the number of data points! \n",
    "    \n",
    "Sure. A large dataset in 3D may very well need $k > 3$.\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
